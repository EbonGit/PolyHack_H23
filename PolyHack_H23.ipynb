{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 485,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hSf8n5zUhA3",
        "outputId": "0c5a5c1c-c3da-407c-8a4d-acfab88ed344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import random\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def binaries_concat(top, bottom, shoes):\n",
        "  \n",
        "  i1 = str(hex(top)).split(\"x\")[1] + str(hex(bottom)).split(\"x\")[1] + str(hex(shoes)).split(\"x\")[1]\n",
        "  i2 = str(hex(bottom)).split(\"x\")[1] + str(hex(shoes)).split(\"x\")[1] + str(hex(top)).split(\"x\")[1]\n",
        "  i3 = str(hex(shoes)).split(\"x\")[1] + str(hex(top)).split(\"x\")[1] + str(hex(bottom)).split(\"x\")[1]\n",
        "  return(int(\"0x\"+i1, 16), int(\"0x\"+i2, 16), int(\"0x\"+i3, 16))\n",
        "\n",
        "binaries_concat(1,3,11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVIUF1RHSu8z",
        "outputId": "1a3b471c-0cc2-42f1-e651-251645ebd548"
      },
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(315, 945, 2835)"
            ]
          },
          "metadata": {},
          "execution_count": 486
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = '/content/out.csv'\n",
        "raw_dataset = pd.read_csv(url, header = 0,\n",
        "                          na_values='?', comment='\\t',\n",
        "                          sep=',', skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()\n",
        "dataset = dataset.dropna()\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ddwe2ImFXzJ4",
        "outputId": "3a867646-5e43-4365-b56b-b4bea7f303e5"
      },
      "execution_count": 487,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     top  bottom  shoes  result\n",
              "0    2.0     2.0    3.0     0.0\n",
              "1    4.0     4.0    1.0     0.0\n",
              "2    4.0     3.0    4.0     0.0\n",
              "3    1.0     4.0    3.0     1.0\n",
              "4    1.0     2.0    2.0     0.0\n",
              "..   ...     ...    ...     ...\n",
              "195  1.0     3.0    4.0     1.0\n",
              "196  4.0     3.0    1.0     1.0\n",
              "197  4.0     4.0    2.0     1.0\n",
              "198  2.0     2.0    1.0     0.0\n",
              "199  4.0     1.0    4.0     0.0\n",
              "\n",
              "[200 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81e9ea80-8f01-4e26-b3b4-05b74491b9cf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>top</th>\n",
              "      <th>bottom</th>\n",
              "      <th>shoes</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81e9ea80-8f01-4e26-b3b4-05b74491b9cf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81e9ea80-8f01-4e26-b3b4-05b74491b9cf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81e9ea80-8f01-4e26-b3b4-05b74491b9cf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 487
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def toInt(s):\n",
        "  return int(s.split(\"_\")[1])\n",
        "\n",
        "def toString(categorie, i):\n",
        "  if(i<10):\n",
        "    return (categorie + \"_00\" + str(i))\n",
        "  elif(i<100):\n",
        "    return (categorie + \"_0\" + str(i))\n",
        "  \n",
        "  return (categorie + \"_\" + str(i))"
      ],
      "metadata": {
        "id": "ksCSBh_vZnRM"
      },
      "execution_count": 488,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def result_analyse(result):\n",
        "  a = result[0][0]\n",
        "  if(a < 0):\n",
        "    return 0\n",
        "  elif(a > 1):\n",
        "    return 1\n",
        "  else:\n",
        "    return round(a)"
      ],
      "metadata": {
        "id": "57f6B53WkLN_"
      },
      "execution_count": 489,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorie = \"top\"\n",
        "print(dataset[categorie][5])\n",
        "print(toString(categorie, dataset[categorie][5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEfodYudZBpg",
        "outputId": "860a563b-790b-4f48-dcfe-11fde18ea449"
      },
      "execution_count": 490,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0\n",
            "top_003.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_tab = []\n",
        "for index, row in dataset.iterrows():\n",
        "    top, bottom, shoes = binaries_concat(round(row[\"top\"]), round(row[\"bottom\"]), round(row[\"shoes\"]))\n",
        "    data_tab.append([top, bottom, shoes, row[\"result\"]])\n",
        "  \n",
        "\n",
        "dataset_ = pd.DataFrame(data_tab)\n",
        "dataset_.columns = [\"top\", \"bottom\", \"shoes\", \"result\"]\n",
        "print(dataset_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_ul9aGbUv4B",
        "outputId": "1f834269-51fd-4bb6-87f1-b2ece9698415"
      },
      "execution_count": 491,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      top  bottom  shoes  result\n",
            "0     547     562    802     0.0\n",
            "1    1089    1044    324     0.0\n",
            "2    1076     836   1091     0.0\n",
            "3     323    1073    788     1.0\n",
            "4     290     545    530     0.0\n",
            "..    ...     ...    ...     ...\n",
            "195   308     833   1043     1.0\n",
            "196  1073     788    323     1.0\n",
            "197  1090    1060    580     1.0\n",
            "198   545     530    290     0.0\n",
            "199  1044     324   1089     0.0\n",
            "\n",
            "[200 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_copy = dataset_.copy()\n",
        "train_labels = train_copy.pop('result')\n",
        "\n",
        "train_features = train_copy[[\"top\", \"bottom\", \"shoes\"]]\n",
        "train_features.describe().transpose()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "FSjPDKrwfuUq",
        "outputId": "a6b446b3-90b8-4cf7-8165-274385594cf5"
      },
      "execution_count": 492,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        count     mean         std    min    25%    50%     75%     max\n",
              "top     200.0  688.130  293.656524  273.0  324.0  786.0  1041.0  1092.0\n",
              "bottom  200.0  711.155  291.927094  273.0  530.0  787.0  1043.0  1092.0\n",
              "shoes   200.0  690.530  302.933230  273.0  324.0  785.0  1043.0  1092.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db55317d-582a-4ab9-9032-205c9fa004f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>200.0</td>\n",
              "      <td>688.130</td>\n",
              "      <td>293.656524</td>\n",
              "      <td>273.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>786.0</td>\n",
              "      <td>1041.0</td>\n",
              "      <td>1092.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bottom</th>\n",
              "      <td>200.0</td>\n",
              "      <td>711.155</td>\n",
              "      <td>291.927094</td>\n",
              "      <td>273.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>787.0</td>\n",
              "      <td>1043.0</td>\n",
              "      <td>1092.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shoes</th>\n",
              "      <td>200.0</td>\n",
              "      <td>690.530</td>\n",
              "      <td>302.933230</td>\n",
              "      <td>273.0</td>\n",
              "      <td>324.0</td>\n",
              "      <td>785.0</td>\n",
              "      <td>1043.0</td>\n",
              "      <td>1092.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db55317d-582a-4ab9-9032-205c9fa004f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db55317d-582a-4ab9-9032-205c9fa004f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db55317d-582a-4ab9-9032-205c9fa004f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 492
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_normalizer = layers.Normalization(axis=-1)\n",
        "features_normalizer.adapt(train_features)\n",
        "\n",
        "#print(features_normalizer[0])\n",
        "print(features_normalizer.mean.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWNX2gtyg-kB",
        "outputId": "da58c627-f6e2-48ec-b158-2aefc3536ed2"
      },
      "execution_count": 493,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[688.13  711.155 690.53 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.GaussianNoise(0.1, seed=None),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "  model.compile(loss='mean_absolute_error',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  return model"
      ],
      "metadata": {
        "id": "t1ttvXloiSK-"
      },
      "execution_count": 494,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(features_normalizer)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMamIRrWiasx",
        "outputId": "4ec7a3c8-e270-4a26-c6e2-971bbbcbe5b2"
      },
      "execution_count": 495,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization_41 (Normaliza  (None, 3)                7         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " gaussian_noise_23 (Gaussian  (None, 3)                0         \n",
            " Noise)                                                          \n",
            "                                                                 \n",
            " dense_249 (Dense)           (None, 64)                256       \n",
            "                                                                 \n",
            " dense_250 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_251 (Dense)           (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_252 (Dense)           (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,648\n",
            "Trainable params: 8,641\n",
            "Non-trainable params: 7\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 1])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "metadata": {
        "id": "kN8foVkWi_jV"
      },
      "execution_count": 496,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=1, epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT4ej-MHijrW",
        "outputId": "9283da6a-58fd-45dc-fc7f-34addbd4608f"
      },
      "execution_count": 497,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "5/5 [==============================] - 1s 45ms/step - loss: 0.5021 - val_loss: 0.5258\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4884 - val_loss: 0.5449\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4695 - val_loss: 0.5505\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.4661 - val_loss: 0.5614\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4541 - val_loss: 0.5607\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4470 - val_loss: 0.5533\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4434 - val_loss: 0.5552\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4385 - val_loss: 0.5545\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4308 - val_loss: 0.5548\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4261 - val_loss: 0.5596\n",
            "Epoch 11/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4274 - val_loss: 0.5537\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4197 - val_loss: 0.5615\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4261 - val_loss: 0.5597\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4193 - val_loss: 0.5530\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4133 - val_loss: 0.5466\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4164 - val_loss: 0.5457\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4105 - val_loss: 0.5500\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4093 - val_loss: 0.5462\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.4133 - val_loss: 0.5477\n",
            "Epoch 20/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4045 - val_loss: 0.5531\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4024 - val_loss: 0.5531\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3997 - val_loss: 0.5450\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3969 - val_loss: 0.5416\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3972 - val_loss: 0.5384\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3888 - val_loss: 0.5436\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4000 - val_loss: 0.5428\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3968 - val_loss: 0.5364\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3838 - val_loss: 0.5345\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3801 - val_loss: 0.5345\n",
            "Epoch 30/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3831 - val_loss: 0.5349\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3834 - val_loss: 0.5245\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3694 - val_loss: 0.5332\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3789 - val_loss: 0.5332\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3683 - val_loss: 0.5276\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3681 - val_loss: 0.5307\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3727 - val_loss: 0.5200\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3667 - val_loss: 0.5222\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3613 - val_loss: 0.5192\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3541 - val_loss: 0.5096\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3595 - val_loss: 0.5041\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3503 - val_loss: 0.5088\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3584 - val_loss: 0.5223\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3538 - val_loss: 0.5001\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3540 - val_loss: 0.4767\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3585 - val_loss: 0.4885\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3447 - val_loss: 0.4773\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3452 - val_loss: 0.4886\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3337 - val_loss: 0.4803\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3378 - val_loss: 0.4726\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3393 - val_loss: 0.4698\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3319 - val_loss: 0.4846\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3381 - val_loss: 0.4672\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3234 - val_loss: 0.4671\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3221 - val_loss: 0.4672\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3136 - val_loss: 0.4546\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3254 - val_loss: 0.4454\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3264 - val_loss: 0.4439\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3184 - val_loss: 0.4500\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3098 - val_loss: 0.4327\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3079 - val_loss: 0.4206\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2987 - val_loss: 0.4183\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3052 - val_loss: 0.4130\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2998 - val_loss: 0.4091\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2989 - val_loss: 0.4100\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2836 - val_loss: 0.4014\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2762 - val_loss: 0.3879\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2743 - val_loss: 0.3870\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2839 - val_loss: 0.3718\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2830 - val_loss: 0.3703\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2684 - val_loss: 0.3866\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2776 - val_loss: 0.3701\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2691 - val_loss: 0.3572\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2809 - val_loss: 0.3454\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2888 - val_loss: 0.3660\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2658 - val_loss: 0.3876\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2607 - val_loss: 0.3402\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2539 - val_loss: 0.3242\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2632 - val_loss: 0.3189\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2484 - val_loss: 0.3256\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2502 - val_loss: 0.3310\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2509 - val_loss: 0.3276\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2412 - val_loss: 0.3102\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2349 - val_loss: 0.3044\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2346 - val_loss: 0.3009\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.2338 - val_loss: 0.2979\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2313 - val_loss: 0.2839\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2284 - val_loss: 0.2745\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2205 - val_loss: 0.2680\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2262 - val_loss: 0.2831\n",
            "Epoch 90/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2169 - val_loss: 0.2703\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1995 - val_loss: 0.2678\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2266 - val_loss: 0.2594\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2195 - val_loss: 0.2846\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2006 - val_loss: 0.2802\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2084 - val_loss: 0.2698\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2056 - val_loss: 0.2612\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2132 - val_loss: 0.2418\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2060 - val_loss: 0.2559\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2007 - val_loss: 0.2559\n",
            "Epoch 100/1000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.1938 - val_loss: 0.2607\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1941 - val_loss: 0.2692\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1992 - val_loss: 0.2501\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1787 - val_loss: 0.2427\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1699 - val_loss: 0.2454\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1829 - val_loss: 0.2563\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1824 - val_loss: 0.2205\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1781 - val_loss: 0.2360\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1707 - val_loss: 0.2394\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1574 - val_loss: 0.2239\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1732 - val_loss: 0.2666\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1883 - val_loss: 0.2104\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1567 - val_loss: 0.2011\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1537 - val_loss: 0.1911\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1498 - val_loss: 0.2263\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1643 - val_loss: 0.2387\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1677 - val_loss: 0.2272\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1875 - val_loss: 0.2813\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2029 - val_loss: 0.2093\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1826 - val_loss: 0.2277\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1539 - val_loss: 0.1796\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1427 - val_loss: 0.2145\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1487 - val_loss: 0.2281\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1562 - val_loss: 0.1923\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1588 - val_loss: 0.1980\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1417 - val_loss: 0.2262\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1456 - val_loss: 0.2034\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1423 - val_loss: 0.2060\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1414 - val_loss: 0.2071\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1485 - val_loss: 0.2184\n",
            "Epoch 130/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1493 - val_loss: 0.2252\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1639 - val_loss: 0.1896\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1459 - val_loss: 0.1936\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1464 - val_loss: 0.1901\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1443 - val_loss: 0.2041\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1311 - val_loss: 0.2154\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1398 - val_loss: 0.1909\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1483 - val_loss: 0.2161\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1482 - val_loss: 0.1878\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1537 - val_loss: 0.2314\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1417 - val_loss: 0.2053\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1524 - val_loss: 0.2390\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1488 - val_loss: 0.2219\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1421 - val_loss: 0.2369\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1455 - val_loss: 0.2316\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1397 - val_loss: 0.2898\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1770 - val_loss: 0.1865\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1375 - val_loss: 0.2181\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1537 - val_loss: 0.1938\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1634 - val_loss: 0.1686\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1514 - val_loss: 0.1830\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1551 - val_loss: 0.1631\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1268 - val_loss: 0.1874\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1222 - val_loss: 0.1722\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1208 - val_loss: 0.1759\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1160 - val_loss: 0.1856\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1200 - val_loss: 0.1581\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1167 - val_loss: 0.1976\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1291 - val_loss: 0.1571\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1160 - val_loss: 0.1664\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1144 - val_loss: 0.1823\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1060 - val_loss: 0.1606\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1008 - val_loss: 0.1573\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1060 - val_loss: 0.1870\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1273 - val_loss: 0.1572\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1193 - val_loss: 0.2039\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1159 - val_loss: 0.1804\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1228 - val_loss: 0.1705\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1037 - val_loss: 0.1539\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1228 - val_loss: 0.1830\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1310 - val_loss: 0.1603\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1264 - val_loss: 0.2234\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1292 - val_loss: 0.1590\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0949 - val_loss: 0.1668\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1155 - val_loss: 0.1696\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1163 - val_loss: 0.1620\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1043 - val_loss: 0.1841\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1280 - val_loss: 0.1736\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1219 - val_loss: 0.1741\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1017 - val_loss: 0.1684\n",
            "Epoch 180/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1139 - val_loss: 0.1563\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.1149 - val_loss: 0.1528\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0984 - val_loss: 0.1813\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.1095 - val_loss: 0.1864\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0970 - val_loss: 0.1703\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1025 - val_loss: 0.1451\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1037 - val_loss: 0.1579\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1219 - val_loss: 0.1748\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1084 - val_loss: 0.1548\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0937 - val_loss: 0.1564\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0965 - val_loss: 0.1568\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.1026 - val_loss: 0.1602\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1081 - val_loss: 0.1649\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0880 - val_loss: 0.1666\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1030 - val_loss: 0.1613\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1115 - val_loss: 0.1522\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0972 - val_loss: 0.1523\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1064 - val_loss: 0.1713\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0943 - val_loss: 0.1480\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0889 - val_loss: 0.1674\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0993 - val_loss: 0.1571\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1121 - val_loss: 0.1543\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1066 - val_loss: 0.1748\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1017 - val_loss: 0.1465\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1084 - val_loss: 0.1641\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.1071 - val_loss: 0.1915\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1207 - val_loss: 0.2075\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1132 - val_loss: 0.1751\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1044 - val_loss: 0.1709\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1068 - val_loss: 0.1679\n",
            "Epoch 210/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1283 - val_loss: 0.1892\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1103 - val_loss: 0.1781\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1075 - val_loss: 0.1879\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1027 - val_loss: 0.1570\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1099 - val_loss: 0.1548\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0971 - val_loss: 0.1310\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0969 - val_loss: 0.1506\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0967 - val_loss: 0.1434\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0874 - val_loss: 0.1425\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0993 - val_loss: 0.1598\n",
            "Epoch 220/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1123 - val_loss: 0.1597\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0860 - val_loss: 0.1646\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1042 - val_loss: 0.1528\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1069 - val_loss: 0.1472\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0788 - val_loss: 0.1414\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0983 - val_loss: 0.1456\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1091 - val_loss: 0.1657\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0986 - val_loss: 0.1663\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1134 - val_loss: 0.1806\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0973 - val_loss: 0.1777\n",
            "Epoch 230/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1019 - val_loss: 0.1858\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1122 - val_loss: 0.1664\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1063 - val_loss: 0.1582\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0993 - val_loss: 0.1443\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0954 - val_loss: 0.1438\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0991 - val_loss: 0.1663\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0966 - val_loss: 0.1416\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0869 - val_loss: 0.1396\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0937 - val_loss: 0.1376\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0867 - val_loss: 0.1473\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0868 - val_loss: 0.1387\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0936 - val_loss: 0.1503\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0900 - val_loss: 0.1541\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1009 - val_loss: 0.1298\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0963 - val_loss: 0.1562\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0844 - val_loss: 0.1787\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0937 - val_loss: 0.1663\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0954 - val_loss: 0.1541\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1022 - val_loss: 0.1712\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0871 - val_loss: 0.1499\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1015 - val_loss: 0.1629\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0918 - val_loss: 0.1571\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0888 - val_loss: 0.1552\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0792 - val_loss: 0.1485\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0909 - val_loss: 0.1472\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0948 - val_loss: 0.1443\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0838 - val_loss: 0.1494\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0911 - val_loss: 0.1438\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0884 - val_loss: 0.1482\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0935 - val_loss: 0.1462\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0838 - val_loss: 0.1433\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1022 - val_loss: 0.1672\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1110 - val_loss: 0.1479\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0917 - val_loss: 0.1432\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0970 - val_loss: 0.1379\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0897 - val_loss: 0.1256\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0813 - val_loss: 0.1426\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0889 - val_loss: 0.1644\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1031 - val_loss: 0.1450\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0923 - val_loss: 0.1304\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0829 - val_loss: 0.1458\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0956 - val_loss: 0.1459\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0922 - val_loss: 0.1393\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0903 - val_loss: 0.1460\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0861 - val_loss: 0.1427\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0742 - val_loss: 0.1366\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0708 - val_loss: 0.1505\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0872 - val_loss: 0.1532\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0905 - val_loss: 0.1479\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0751 - val_loss: 0.1348\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0784 - val_loss: 0.1523\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0732 - val_loss: 0.1355\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0874 - val_loss: 0.1486\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0814 - val_loss: 0.1332\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0915 - val_loss: 0.1344\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0848 - val_loss: 0.1413\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0838 - val_loss: 0.1354\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0900 - val_loss: 0.1476\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0917 - val_loss: 0.1443\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0908 - val_loss: 0.1535\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0997 - val_loss: 0.1305\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1046 - val_loss: 0.1645\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0973 - val_loss: 0.1655\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0876 - val_loss: 0.1618\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0894 - val_loss: 0.1529\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1005 - val_loss: 0.1685\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0959 - val_loss: 0.1511\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0978 - val_loss: 0.1587\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0787 - val_loss: 0.1241\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0797 - val_loss: 0.1439\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0844 - val_loss: 0.1349\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0897 - val_loss: 0.1475\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0829 - val_loss: 0.1627\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0796 - val_loss: 0.1279\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0671 - val_loss: 0.1327\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0758 - val_loss: 0.1403\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0822 - val_loss: 0.1263\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0709 - val_loss: 0.1314\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0761 - val_loss: 0.1253\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0803 - val_loss: 0.1327\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0828 - val_loss: 0.1230\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0897 - val_loss: 0.1259\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0774 - val_loss: 0.1360\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0750 - val_loss: 0.1401\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0807 - val_loss: 0.1365\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0874 - val_loss: 0.1494\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0937 - val_loss: 0.1363\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0710 - val_loss: 0.1554\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0927 - val_loss: 0.1411\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0814 - val_loss: 0.1426\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0738 - val_loss: 0.1537\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0875 - val_loss: 0.1309\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0803 - val_loss: 0.1242\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0790 - val_loss: 0.1328\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0776 - val_loss: 0.1372\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0772 - val_loss: 0.1320\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0834 - val_loss: 0.1495\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0812 - val_loss: 0.1303\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0858 - val_loss: 0.1575\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0757 - val_loss: 0.1312\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0857 - val_loss: 0.1415\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0861 - val_loss: 0.1290\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0726 - val_loss: 0.1269\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0717 - val_loss: 0.1730\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0791 - val_loss: 0.1356\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0876 - val_loss: 0.1542\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0726 - val_loss: 0.1213\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0680 - val_loss: 0.1296\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0755 - val_loss: 0.1258\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0845 - val_loss: 0.1399\n",
            "Epoch 340/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0794 - val_loss: 0.1188\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0809 - val_loss: 0.1400\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0710 - val_loss: 0.1477\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0808 - val_loss: 0.1598\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0996 - val_loss: 0.1246\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0947 - val_loss: 0.1414\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0732 - val_loss: 0.1444\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0782 - val_loss: 0.1261\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0877 - val_loss: 0.1231\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0737 - val_loss: 0.1354\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0854 - val_loss: 0.1246\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0812 - val_loss: 0.1358\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0763 - val_loss: 0.1430\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0699 - val_loss: 0.1205\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0684 - val_loss: 0.1280\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0776 - val_loss: 0.1237\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0760 - val_loss: 0.1297\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0778 - val_loss: 0.1223\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0743 - val_loss: 0.1354\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0769 - val_loss: 0.1450\n",
            "Epoch 360/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0774 - val_loss: 0.1320\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1024 - val_loss: 0.1683\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0926 - val_loss: 0.1566\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0975 - val_loss: 0.1444\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1051 - val_loss: 0.1520\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0919 - val_loss: 0.1439\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0727 - val_loss: 0.1363\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0897 - val_loss: 0.1325\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0711 - val_loss: 0.1499\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0794 - val_loss: 0.1505\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0888 - val_loss: 0.1571\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0893 - val_loss: 0.1525\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0828 - val_loss: 0.1414\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0707 - val_loss: 0.1214\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0661 - val_loss: 0.1278\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0621 - val_loss: 0.1170\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0622 - val_loss: 0.1426\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0710 - val_loss: 0.1295\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0711 - val_loss: 0.1275\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0609 - val_loss: 0.1301\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0693 - val_loss: 0.1339\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0921 - val_loss: 0.1587\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0751 - val_loss: 0.1394\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0801 - val_loss: 0.1396\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0765 - val_loss: 0.1334\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0819 - val_loss: 0.1320\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0740 - val_loss: 0.1582\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0795 - val_loss: 0.1241\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0851 - val_loss: 0.1172\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0767 - val_loss: 0.1535\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0892 - val_loss: 0.1544\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0736 - val_loss: 0.1332\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0740 - val_loss: 0.1550\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0825 - val_loss: 0.1317\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0655 - val_loss: 0.1246\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0685 - val_loss: 0.1579\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0799 - val_loss: 0.1337\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0871 - val_loss: 0.1523\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0760 - val_loss: 0.1275\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0909 - val_loss: 0.1484\n",
            "Epoch 400/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0709 - val_loss: 0.1209\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0743 - val_loss: 0.1504\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0865 - val_loss: 0.1330\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0775 - val_loss: 0.1358\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0704 - val_loss: 0.1273\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0670 - val_loss: 0.1176\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0681 - val_loss: 0.1263\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0754 - val_loss: 0.1368\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0676 - val_loss: 0.1412\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0729 - val_loss: 0.1365\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0716 - val_loss: 0.1335\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0810 - val_loss: 0.1457\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0749 - val_loss: 0.1208\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0652 - val_loss: 0.1360\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0689 - val_loss: 0.1337\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0658 - val_loss: 0.1314\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0793 - val_loss: 0.1328\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0703 - val_loss: 0.1231\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0726 - val_loss: 0.1375\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0762 - val_loss: 0.1302\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0661 - val_loss: 0.1222\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 0s 29ms/step - loss: 0.0736 - val_loss: 0.1322\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0771 - val_loss: 0.1249\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0731 - val_loss: 0.1408\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0775 - val_loss: 0.1341\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0734 - val_loss: 0.1252\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0839 - val_loss: 0.1326\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0751 - val_loss: 0.1219\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0709 - val_loss: 0.1270\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0726 - val_loss: 0.1147\n",
            "Epoch 430/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0578 - val_loss: 0.1247\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0737 - val_loss: 0.1357\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0637 - val_loss: 0.1326\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0739 - val_loss: 0.1309\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0811 - val_loss: 0.1173\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0676 - val_loss: 0.1296\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0707 - val_loss: 0.1633\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0686 - val_loss: 0.1266\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0688 - val_loss: 0.1255\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0678 - val_loss: 0.1340\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0821 - val_loss: 0.1246\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0655 - val_loss: 0.1236\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0615 - val_loss: 0.1277\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0704 - val_loss: 0.1276\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0562 - val_loss: 0.1197\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0783 - val_loss: 0.1186\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0590 - val_loss: 0.1303\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0743 - val_loss: 0.1183\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0672 - val_loss: 0.1242\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0610 - val_loss: 0.1303\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0762 - val_loss: 0.1208\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0695 - val_loss: 0.1481\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0726 - val_loss: 0.1369\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0664 - val_loss: 0.1459\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0865 - val_loss: 0.1388\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0858 - val_loss: 0.1449\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0757 - val_loss: 0.1196\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0822 - val_loss: 0.1369\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0654 - val_loss: 0.1295\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0660 - val_loss: 0.1259\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0755 - val_loss: 0.1433\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0752 - val_loss: 0.1237\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0642 - val_loss: 0.1243\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0682 - val_loss: 0.1385\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0730 - val_loss: 0.1386\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0608 - val_loss: 0.1231\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0687 - val_loss: 0.1257\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0702 - val_loss: 0.1134\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0780 - val_loss: 0.1287\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0611 - val_loss: 0.1226\n",
            "Epoch 470/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0668 - val_loss: 0.1334\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0685 - val_loss: 0.1230\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0770 - val_loss: 0.1349\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0605 - val_loss: 0.1130\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0609 - val_loss: 0.1119\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0642 - val_loss: 0.1248\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0591 - val_loss: 0.1229\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0694 - val_loss: 0.1209\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0591 - val_loss: 0.1384\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0713 - val_loss: 0.1202\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0561 - val_loss: 0.1308\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0832 - val_loss: 0.1372\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0685 - val_loss: 0.1316\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0689 - val_loss: 0.1487\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0725 - val_loss: 0.1296\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0703 - val_loss: 0.1314\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0761 - val_loss: 0.1275\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0631 - val_loss: 0.1133\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0647 - val_loss: 0.1237\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0790 - val_loss: 0.1627\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0754 - val_loss: 0.1392\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0608 - val_loss: 0.1355\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0833 - val_loss: 0.1282\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0668 - val_loss: 0.1337\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0701 - val_loss: 0.1448\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0718 - val_loss: 0.1240\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0695 - val_loss: 0.1305\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0670 - val_loss: 0.1299\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0676 - val_loss: 0.1272\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0591 - val_loss: 0.1188\n",
            "Epoch 500/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0722 - val_loss: 0.1287\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0703 - val_loss: 0.1513\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0742 - val_loss: 0.1315\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0753 - val_loss: 0.1210\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0725 - val_loss: 0.1065\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0633 - val_loss: 0.1568\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0738 - val_loss: 0.1350\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0792 - val_loss: 0.1356\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0670 - val_loss: 0.1583\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0898 - val_loss: 0.1199\n",
            "Epoch 510/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0885 - val_loss: 0.1534\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0692 - val_loss: 0.1567\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0864 - val_loss: 0.1594\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0644 - val_loss: 0.1230\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0783 - val_loss: 0.1258\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0820 - val_loss: 0.1279\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0636 - val_loss: 0.1363\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0713 - val_loss: 0.1329\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0725 - val_loss: 0.1189\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0616 - val_loss: 0.1266\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0662 - val_loss: 0.1216\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0571 - val_loss: 0.1151\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0529 - val_loss: 0.1244\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0646 - val_loss: 0.1149\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0607 - val_loss: 0.1271\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0657 - val_loss: 0.1291\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0674 - val_loss: 0.1284\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0646 - val_loss: 0.1207\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0656 - val_loss: 0.1311\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0586 - val_loss: 0.1222\n",
            "Epoch 530/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0599 - val_loss: 0.1269\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0714 - val_loss: 0.1408\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0632 - val_loss: 0.1449\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0708 - val_loss: 0.1268\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0696 - val_loss: 0.1206\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0685 - val_loss: 0.1119\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0616 - val_loss: 0.1255\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0662 - val_loss: 0.1477\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0688 - val_loss: 0.1389\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0606 - val_loss: 0.1337\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0594 - val_loss: 0.1171\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0647 - val_loss: 0.1287\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0621 - val_loss: 0.1270\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0714 - val_loss: 0.1148\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0662 - val_loss: 0.1427\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0675 - val_loss: 0.1302\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0688 - val_loss: 0.1315\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0670 - val_loss: 0.1307\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0693 - val_loss: 0.1207\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0617 - val_loss: 0.1128\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0705 - val_loss: 0.1132\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0633 - val_loss: 0.1466\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0763 - val_loss: 0.1142\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0685 - val_loss: 0.1122\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0648 - val_loss: 0.1407\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0797 - val_loss: 0.1275\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0681 - val_loss: 0.1348\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0760 - val_loss: 0.1458\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0677 - val_loss: 0.1479\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0599 - val_loss: 0.1258\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0636 - val_loss: 0.1126\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0637 - val_loss: 0.1154\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0699 - val_loss: 0.1201\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0672 - val_loss: 0.1198\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0606 - val_loss: 0.1193\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0711 - val_loss: 0.1103\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0641 - val_loss: 0.1117\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0677 - val_loss: 0.1257\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0642 - val_loss: 0.1266\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0746 - val_loss: 0.1225\n",
            "Epoch 570/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0601 - val_loss: 0.1153\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0549 - val_loss: 0.1219\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0540 - val_loss: 0.1227\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0621 - val_loss: 0.1197\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0597 - val_loss: 0.1210\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0636 - val_loss: 0.1270\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0687 - val_loss: 0.1399\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0637 - val_loss: 0.1148\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0659 - val_loss: 0.1333\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0681 - val_loss: 0.1207\n",
            "Epoch 580/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0654 - val_loss: 0.1337\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0630 - val_loss: 0.1231\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0611 - val_loss: 0.1097\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0637 - val_loss: 0.1272\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0667 - val_loss: 0.1147\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0646 - val_loss: 0.1100\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0705 - val_loss: 0.1196\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0721 - val_loss: 0.1082\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0639 - val_loss: 0.1240\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0637 - val_loss: 0.1134\n",
            "Epoch 590/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0636 - val_loss: 0.1122\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0676 - val_loss: 0.1244\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0594 - val_loss: 0.1127\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0583 - val_loss: 0.1283\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0499 - val_loss: 0.1314\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0592 - val_loss: 0.1282\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0614 - val_loss: 0.1351\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0612 - val_loss: 0.1159\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0609 - val_loss: 0.1297\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0813 - val_loss: 0.1014\n",
            "Epoch 600/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0786 - val_loss: 0.1262\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0630 - val_loss: 0.1241\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0548 - val_loss: 0.1289\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0721 - val_loss: 0.1079\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0625 - val_loss: 0.1158\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0704 - val_loss: 0.1111\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0588 - val_loss: 0.1228\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0599 - val_loss: 0.1164\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0660 - val_loss: 0.1267\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0711 - val_loss: 0.1327\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0560 - val_loss: 0.1358\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0568 - val_loss: 0.1109\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0688 - val_loss: 0.1335\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0682 - val_loss: 0.1461\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0709 - val_loss: 0.1230\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0600 - val_loss: 0.1070\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0577 - val_loss: 0.1229\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0568 - val_loss: 0.1056\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0673 - val_loss: 0.1153\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0679 - val_loss: 0.1120\n",
            "Epoch 620/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0445 - val_loss: 0.1199\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0647 - val_loss: 0.1129\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0565 - val_loss: 0.1017\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0616 - val_loss: 0.1086\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0596 - val_loss: 0.1217\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0644 - val_loss: 0.1288\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0580 - val_loss: 0.1413\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0679 - val_loss: 0.1242\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0633 - val_loss: 0.1171\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0561 - val_loss: 0.1194\n",
            "Epoch 630/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0544 - val_loss: 0.1140\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0560 - val_loss: 0.1066\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0614 - val_loss: 0.1149\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0573 - val_loss: 0.1075\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0571 - val_loss: 0.1204\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0608 - val_loss: 0.1313\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0619 - val_loss: 0.1224\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0600 - val_loss: 0.1479\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0551 - val_loss: 0.1163\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0639 - val_loss: 0.1336\n",
            "Epoch 640/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0649 - val_loss: 0.1174\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0770 - val_loss: 0.1280\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0750 - val_loss: 0.1243\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0698 - val_loss: 0.1426\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0615 - val_loss: 0.1292\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0757 - val_loss: 0.1148\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0653 - val_loss: 0.1270\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0629 - val_loss: 0.1375\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0606 - val_loss: 0.1185\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0562 - val_loss: 0.1122\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0616 - val_loss: 0.1287\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0640 - val_loss: 0.1311\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0796 - val_loss: 0.1100\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0624 - val_loss: 0.1271\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0682 - val_loss: 0.1311\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0644 - val_loss: 0.1179\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0733 - val_loss: 0.1210\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0703 - val_loss: 0.1261\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0749 - val_loss: 0.1131\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0685 - val_loss: 0.1323\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0597 - val_loss: 0.1179\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0683 - val_loss: 0.1391\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0520 - val_loss: 0.1299\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0533 - val_loss: 0.1150\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0577 - val_loss: 0.1152\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0645 - val_loss: 0.1197\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0613 - val_loss: 0.1208\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0611 - val_loss: 0.1257\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0499 - val_loss: 0.1147\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0580 - val_loss: 0.1181\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0574 - val_loss: 0.1287\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0570 - val_loss: 0.1240\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0645 - val_loss: 0.1313\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0637 - val_loss: 0.1217\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0582 - val_loss: 0.1222\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0639 - val_loss: 0.1133\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0478 - val_loss: 0.1291\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0548 - val_loss: 0.1182\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0582 - val_loss: 0.1069\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0543 - val_loss: 0.1238\n",
            "Epoch 680/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0512 - val_loss: 0.1343\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0614 - val_loss: 0.1227\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0574 - val_loss: 0.1172\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0524 - val_loss: 0.1187\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0584 - val_loss: 0.1182\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0545 - val_loss: 0.1130\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0478 - val_loss: 0.1088\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0564 - val_loss: 0.1273\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0597 - val_loss: 0.1152\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0639 - val_loss: 0.1314\n",
            "Epoch 690/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0654 - val_loss: 0.1249\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0664 - val_loss: 0.1530\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0743 - val_loss: 0.1439\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0783 - val_loss: 0.1332\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0741 - val_loss: 0.1295\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0615 - val_loss: 0.1590\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0656 - val_loss: 0.1259\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0761 - val_loss: 0.1382\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0659 - val_loss: 0.1306\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0789 - val_loss: 0.1511\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0681 - val_loss: 0.1381\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0704 - val_loss: 0.1481\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0577 - val_loss: 0.1091\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0573 - val_loss: 0.1460\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0618 - val_loss: 0.1245\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0567 - val_loss: 0.1094\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0601 - val_loss: 0.1202\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0506 - val_loss: 0.1181\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0672 - val_loss: 0.1332\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0629 - val_loss: 0.1112\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0560 - val_loss: 0.1389\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0617 - val_loss: 0.1081\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0566 - val_loss: 0.1301\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0563 - val_loss: 0.1081\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0616 - val_loss: 0.1210\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0678 - val_loss: 0.1273\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0592 - val_loss: 0.1169\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0508 - val_loss: 0.1155\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0521 - val_loss: 0.1148\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0526 - val_loss: 0.1058\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0516 - val_loss: 0.1210\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0591 - val_loss: 0.1422\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0612 - val_loss: 0.1075\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0633 - val_loss: 0.1199\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0486 - val_loss: 0.1141\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0562 - val_loss: 0.1181\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0607 - val_loss: 0.1196\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0624 - val_loss: 0.1130\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0547 - val_loss: 0.1284\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0510 - val_loss: 0.1174\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0685 - val_loss: 0.1386\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0557 - val_loss: 0.1232\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0605 - val_loss: 0.1185\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0740 - val_loss: 0.1314\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0747 - val_loss: 0.1410\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0534 - val_loss: 0.1246\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0658 - val_loss: 0.1298\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0512 - val_loss: 0.1231\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0506 - val_loss: 0.1135\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0609 - val_loss: 0.1226\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0522 - val_loss: 0.1067\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0503 - val_loss: 0.1420\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0652 - val_loss: 0.1138\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0709 - val_loss: 0.1471\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0664 - val_loss: 0.1452\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0731 - val_loss: 0.1516\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0795 - val_loss: 0.1353\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0898 - val_loss: 0.1619\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0784 - val_loss: 0.1350\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0671 - val_loss: 0.1386\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0715 - val_loss: 0.1323\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0675 - val_loss: 0.1486\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0562 - val_loss: 0.1341\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0632 - val_loss: 0.1334\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0571 - val_loss: 0.1127\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0603 - val_loss: 0.1306\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0726 - val_loss: 0.1158\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0601 - val_loss: 0.1151\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0560 - val_loss: 0.1128\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0591 - val_loss: 0.1219\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0619 - val_loss: 0.1152\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0549 - val_loss: 0.1162\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0601 - val_loss: 0.1296\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0555 - val_loss: 0.1094\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0646 - val_loss: 0.1170\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0583 - val_loss: 0.1237\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0566 - val_loss: 0.1223\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0544 - val_loss: 0.1133\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0639 - val_loss: 0.1241\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0574 - val_loss: 0.1087\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0552 - val_loss: 0.1254\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0742 - val_loss: 0.1204\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0566 - val_loss: 0.1135\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0503 - val_loss: 0.1155\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0580 - val_loss: 0.1175\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0612 - val_loss: 0.1216\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0653 - val_loss: 0.1101\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0538 - val_loss: 0.1142\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0504 - val_loss: 0.1327\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0661 - val_loss: 0.1169\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0597 - val_loss: 0.1176\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0632 - val_loss: 0.1168\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0589 - val_loss: 0.1164\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0578 - val_loss: 0.1193\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0590 - val_loss: 0.1219\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0568 - val_loss: 0.1164\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0637 - val_loss: 0.1217\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0647 - val_loss: 0.1490\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0707 - val_loss: 0.1078\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0570 - val_loss: 0.1171\n",
            "Epoch 790/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0499 - val_loss: 0.1192\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0634 - val_loss: 0.1347\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0606 - val_loss: 0.1245\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0535 - val_loss: 0.1196\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0576 - val_loss: 0.1238\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0599 - val_loss: 0.1335\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0511 - val_loss: 0.1192\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0516 - val_loss: 0.1145\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0463 - val_loss: 0.1215\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0601 - val_loss: 0.1525\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0694 - val_loss: 0.1302\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0583 - val_loss: 0.1521\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0553 - val_loss: 0.1092\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0618 - val_loss: 0.1187\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0675 - val_loss: 0.1508\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0703 - val_loss: 0.1206\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0542 - val_loss: 0.1105\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0496 - val_loss: 0.1269\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0650 - val_loss: 0.1077\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0563 - val_loss: 0.1396\n",
            "Epoch 810/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0537 - val_loss: 0.1162\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0627 - val_loss: 0.1345\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0510 - val_loss: 0.1317\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0625 - val_loss: 0.1176\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0612 - val_loss: 0.1200\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0621 - val_loss: 0.1222\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0522 - val_loss: 0.1379\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0639 - val_loss: 0.1259\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0645 - val_loss: 0.1162\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0522 - val_loss: 0.1182\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0593 - val_loss: 0.1188\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0472 - val_loss: 0.1195\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0605 - val_loss: 0.1112\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0566 - val_loss: 0.1116\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0564 - val_loss: 0.1332\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0669 - val_loss: 0.1095\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0596 - val_loss: 0.1198\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0686 - val_loss: 0.1211\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0518 - val_loss: 0.1127\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0457 - val_loss: 0.1153\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0445 - val_loss: 0.1118\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0556 - val_loss: 0.1183\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0480 - val_loss: 0.1177\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0524 - val_loss: 0.1189\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0639 - val_loss: 0.1062\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0508 - val_loss: 0.1337\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0627 - val_loss: 0.1172\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0569 - val_loss: 0.1078\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0607 - val_loss: 0.1102\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0497 - val_loss: 0.1189\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0440 - val_loss: 0.1325\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0558 - val_loss: 0.1177\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0585 - val_loss: 0.1420\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0651 - val_loss: 0.1224\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0538 - val_loss: 0.1224\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0615 - val_loss: 0.1224\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0488 - val_loss: 0.1187\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0563 - val_loss: 0.1097\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0638 - val_loss: 0.1314\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0588 - val_loss: 0.1140\n",
            "Epoch 850/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0563 - val_loss: 0.1348\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0571 - val_loss: 0.1358\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0677 - val_loss: 0.1361\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0733 - val_loss: 0.1262\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0704 - val_loss: 0.1279\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0602 - val_loss: 0.1192\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0473 - val_loss: 0.1249\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0584 - val_loss: 0.1163\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0574 - val_loss: 0.1144\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0490 - val_loss: 0.1449\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0540 - val_loss: 0.1230\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0587 - val_loss: 0.1151\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0502 - val_loss: 0.1216\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0549 - val_loss: 0.1241\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0559 - val_loss: 0.1347\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0566 - val_loss: 0.1170\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0565 - val_loss: 0.1148\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0551 - val_loss: 0.1151\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0599 - val_loss: 0.1152\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0639 - val_loss: 0.1255\n",
            "Epoch 870/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0602 - val_loss: 0.1242\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0582 - val_loss: 0.1321\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0632 - val_loss: 0.1252\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0602 - val_loss: 0.1278\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0563 - val_loss: 0.1221\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0511 - val_loss: 0.1142\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0504 - val_loss: 0.1201\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0541 - val_loss: 0.1265\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0464 - val_loss: 0.1232\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0562 - val_loss: 0.1224\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0591 - val_loss: 0.1163\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0579 - val_loss: 0.1212\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0563 - val_loss: 0.1170\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0647 - val_loss: 0.1166\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0464 - val_loss: 0.1108\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0515 - val_loss: 0.1066\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0504 - val_loss: 0.1096\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0532 - val_loss: 0.1092\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0594 - val_loss: 0.1174\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0533 - val_loss: 0.1358\n",
            "Epoch 890/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0546 - val_loss: 0.1150\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0603 - val_loss: 0.1311\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0568 - val_loss: 0.1292\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0654 - val_loss: 0.1226\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0579 - val_loss: 0.1251\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0555 - val_loss: 0.1207\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0494 - val_loss: 0.1215\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0433 - val_loss: 0.1180\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0578 - val_loss: 0.1075\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0518 - val_loss: 0.1137\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0480 - val_loss: 0.1233\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0549 - val_loss: 0.1373\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0515 - val_loss: 0.1253\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0548 - val_loss: 0.1274\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0651 - val_loss: 0.1166\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0451 - val_loss: 0.1307\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0434 - val_loss: 0.1246\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0505 - val_loss: 0.1281\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0536 - val_loss: 0.1098\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 0s 24ms/step - loss: 0.0465 - val_loss: 0.1115\n",
            "Epoch 910/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0706 - val_loss: 0.1151\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0493 - val_loss: 0.1079\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0466 - val_loss: 0.1129\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0576 - val_loss: 0.1177\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 0s 23ms/step - loss: 0.0550 - val_loss: 0.1127\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 0.0555 - val_loss: 0.1239\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0581 - val_loss: 0.1224\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0545 - val_loss: 0.1244\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 0.0651 - val_loss: 0.1339\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0565 - val_loss: 0.1081\n",
            "Epoch 920/1000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0575 - val_loss: 0.1128\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0542 - val_loss: 0.1273\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0685 - val_loss: 0.1141\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0505 - val_loss: 0.1155\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 0s 21ms/step - loss: 0.0420 - val_loss: 0.1178\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0498 - val_loss: 0.1024\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0467 - val_loss: 0.1128\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0547 - val_loss: 0.1225\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0594 - val_loss: 0.1299\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0617 - val_loss: 0.1489\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0677 - val_loss: 0.1474\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0542 - val_loss: 0.1272\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0719 - val_loss: 0.1265\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0536 - val_loss: 0.1190\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0565 - val_loss: 0.1158\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0541 - val_loss: 0.1336\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0571 - val_loss: 0.1246\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0573 - val_loss: 0.1388\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0600 - val_loss: 0.1220\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0632 - val_loss: 0.1156\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0653 - val_loss: 0.1238\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0572 - val_loss: 0.1164\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0505 - val_loss: 0.1151\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0570 - val_loss: 0.1127\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0602 - val_loss: 0.1171\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0584 - val_loss: 0.1154\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0557 - val_loss: 0.1297\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0598 - val_loss: 0.1237\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0609 - val_loss: 0.1285\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0491 - val_loss: 0.1267\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0517 - val_loss: 0.1275\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0482 - val_loss: 0.1221\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0508 - val_loss: 0.1112\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0453 - val_loss: 0.1255\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0534 - val_loss: 0.1111\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0601 - val_loss: 0.1524\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0685 - val_loss: 0.1587\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0828 - val_loss: 0.1311\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0541 - val_loss: 0.1174\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0476 - val_loss: 0.1122\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0452 - val_loss: 0.1166\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0493 - val_loss: 0.1188\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0533 - val_loss: 0.1171\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0573 - val_loss: 0.1091\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0529 - val_loss: 0.1232\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0497 - val_loss: 0.1178\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0581 - val_loss: 0.1267\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0594 - val_loss: 0.1335\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0579 - val_loss: 0.1311\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0547 - val_loss: 0.1168\n",
            "Epoch 970/1000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0599 - val_loss: 0.1085\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0496 - val_loss: 0.1105\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0538 - val_loss: 0.1213\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0639 - val_loss: 0.1224\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0535 - val_loss: 0.1236\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0543 - val_loss: 0.1104\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0471 - val_loss: 0.1113\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0652 - val_loss: 0.1256\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0488 - val_loss: 0.1151\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0499 - val_loss: 0.1162\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0484 - val_loss: 0.1186\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0410 - val_loss: 0.1209\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0528 - val_loss: 0.1115\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0463 - val_loss: 0.1151\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0430 - val_loss: 0.1137\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0589 - val_loss: 0.1154\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0577 - val_loss: 0.1201\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0577 - val_loss: 0.1202\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0560 - val_loss: 0.1148\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0531 - val_loss: 0.1174\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0559 - val_loss: 0.1175\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0588 - val_loss: 0.1186\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0517 - val_loss: 0.1201\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0556 - val_loss: 0.1137\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0404 - val_loss: 0.1158\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0397 - val_loss: 0.1336\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0531 - val_loss: 0.0985\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0511 - val_loss: 0.1093\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0516 - val_loss: 0.1073\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0471 - val_loss: 0.1222\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0553 - val_loss: 0.1235\n",
            "CPU times: user 47.5 s, sys: 2.14 s, total: 49.6 s\n",
            "Wall time: 1min 22s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "DB8_FzYoiz6z",
        "outputId": "fd10eeb3-faad-41c2-88ac-32d8b07cf413"
      },
      "execution_count": 498,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = 0\n",
        "for j in range(200):\n",
        "    top = random.randint(1, 4)  \n",
        "    bottom = random.randint(1, 4)\n",
        "    shoes = random.randint(1, 4)\n",
        "\n",
        "    top_, bottom_, shoes_ = binaries_concat(top, bottom, shoes)\n",
        "\n",
        "    result = 0\n",
        "\n",
        "    if ((top + bottom + shoes) % 2 == 0):\n",
        "        result = 1\n",
        "\n",
        "    if (result == result_analyse(model.predict([top_,bottom_,shoes_]))):\n",
        "      s+=1\n",
        "    \n",
        "\n",
        "\n",
        "print(s/200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfCwyLa0jj_p",
        "outputId": "adb95c48-4e21-413d-e30a-fb474eaf2be5"
      },
      "execution_count": 499,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, None) for input KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='normalization_41_input'), name='normalization_41_input', description=\"created by layer 'normalization_41_input'\"), but it was called on an input with incompatible shape (None,).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "1/1 [==============================] - 0s 162ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/model.h5')"
      ],
      "metadata": {
        "id": "dN-IzN_zIgEv"
      },
      "execution_count": 500,
      "outputs": []
    }
  ]
}